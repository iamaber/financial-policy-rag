{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7e69468-6ee5-454e-94d7-94f681f0c17f",
   "metadata": {},
   "source": [
    "### Extract Data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6ad90a-8199-4ffb-9ca4-9375840be717",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyPDF2 \n",
    "\n",
    "\"\"\"\n",
    "Could have used OCR like https://github.com/opendatalab/MinerU  \n",
    "if there was many graphs and charts.\n",
    "\"\"\"\n",
    "\n",
    "DATA_DIR = \"../data/For Task - Policy file.pdf\"\n",
    "\n",
    "def extract_text(pdf_path):\n",
    "    text = []\n",
    "    with open(pdf_path, \"rb\") as f:\n",
    "        reader = PyPDF2.PdfReader(f)\n",
    "        for i, page in enumerate(reader.pages, 1):\n",
    "            text.append({\"page\": i, \"content\": page.extract_text()})\n",
    "    return text\n",
    "\n",
    "raw_pages = extract_text(DATA_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "40bf5f0e-8085-4466-b00d-75842d33db65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into chunks keep page & paragraph info for better context\n",
    "\n",
    "\"\"\" \n",
    "Used RecursiveCharacterTextSplitter which is semantic-preserving hierarchical chunking technique.\n",
    "It has citations(pages, paragraph, tabel) which will help me find any error. \n",
    "\"\"\"\n",
    "\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.schema import Document\n",
    "\n",
    "splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000,\n",
    "    chunk_overlap=200,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \".\", \"!\", \"?\"]\n",
    ")\n",
    "\n",
    "docs = []\n",
    "for p in raw_pages:\n",
    "    chunks = splitter.split_text(p[\"content\"])\n",
    "    for para_idx, c in enumerate(chunks, 1):\n",
    "        docs.append(\n",
    "            Document(\n",
    "                page_content=c,\n",
    "                metadata={\"page\": p[\"page\"], \"paragraph\": para_idx}\n",
    "            )\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc6f670-87f0-4b6b-8ae8-bcf5beca4202",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, dotenv\n",
    "\n",
    "dotenv.load_dotenv()\n",
    "genai_api = os.getenv(\"GEMINI_API_KEY\") "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74904bb2-1d9f-404d-ab46-103a7ee28241",
   "metadata": {},
   "source": [
    "### vector store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3654d645-7a27-426a-ae56-0a1079294f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings, ChatGoogleGenerativeAI \n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "# used gemini for as embedding and llm model.\n",
    "embeddings = GoogleGenerativeAIEmbeddings(\n",
    "    model=\"models/embedding-001\",\n",
    "    google_api_key=genai_api\n",
    ")\n",
    "vectorstore = Chroma.from_documents(\n",
    "    docs,\n",
    "    embeddings,\n",
    "    persist_directory=\"../data/chroma_db\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dceb2d68-b068-4d41-ae2f-56fb70ad166b",
   "metadata": {},
   "source": [
    "### Chat Bot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046ed70-796a-40cb-942e-dac094d79c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.0-flash\",\n",
    "    temperature=0.2, # used low temperature as it requires high precision and consistency\n",
    "    google_api_key=genai_api\n",
    ")\n",
    "\n",
    "# Simple prompt but we can add additional rules and use one shot or few shot prompting \n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful assistant for a financial policy document. \"\n",
    "            \"Answer questions and include the exact page & paragraph citations.\\n\\nContext:\\n{context}\",\n",
    "        ),\n",
    "        (\"human\", \"{input}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "qa_chain   = create_stuff_documents_chain(llm, prompt)\n",
    "retriever  = vectorstore.as_retriever()\n",
    "rag_chain  = create_retrieval_chain(retriever, qa_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76f9e9b7-49b7-497a-a0a0-056bf6d496c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conversation memory\n",
    "\n",
    "\n",
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "store = {} # It keeps chat history stored in the session_id\n",
    "chat = RunnableWithMessageHistory(\n",
    "    rag_chain,\n",
    "    lambda sid: store.setdefault(sid, ChatMessageHistory()),\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"answer\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f6ad49f5-5c8a-4635-ba09-50e1171de1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The key financial measures established by the Government satisfy various principles of responsible financial management specified within the Financial Management Act 1996, these are: (a) ensuring that the total liabilities of the Territory are at prudent levels to provide a buffer against factors that may impact adversely on the level of total Territory liabilities in the (see page 1, Principles of Responsible Financial Management, paragraph a).\n"
     ]
    }
   ],
   "source": [
    "# A helper function to get answer from the chat\n",
    "def ask(q, sid=\"default\"):\n",
    "    out = chat.invoke({\"input\": q}, {\"configurable\": {\"session_id\": sid}})\n",
    "    return out[\"answer\"]\n",
    "    \n",
    "print(ask(\"What are the Principles of Responsible Financial Management?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "037a6325-d5b8-498c-9768-81801b7ba512",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The policy focuses on ensuring total liabilities are at prudent levels and that operating expenses do not exceed operating income. (a) and (b)\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"What about debt?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0cc46e9b-a923-488e-a37d-509f7dd0b143",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The Government has a commitment to fund 90% of accrued superannuation liabilities by 30 June 2040 (Page 1.2.6, Paragraph \"90% coverage of accrued superannuation liabilities by 2039-40\").\n"
     ]
    }
   ],
   "source": [
    "print(ask(\"when did the Government has a commitment to fund accrued superannuation liabilities?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22446687-49cd-479b-a250-a41402ddcaa3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
